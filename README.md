# HomoScriptor: A Human-Written Dataset for Language Model Fine-Tuning

HomoScriptor is a unique and curated collection of human-written datasets designed specifically for fine-tuning large language models (LLMs). This repository contains a diverse range of categories, each represented by individual JSON files, allowing you to explore and train LLMs on various linguistic tasks.

## Features

- **High-Quality Human-Written Data**: HomoScriptor offers meticulously crafted instructions and corresponding outputs, ensuring the dataset's reliability and accuracy.
- **Categorized JSON Files**: The dataset is neatly organized, with each category having its own JSON file, making it easy to navigate and incorporate specific linguistic domains into your LLM training pipeline.
- **Short and Long Variant Outputs**: Each task in the JSON files includes both short and long variant outputs, providing flexibility based on your specific needs.
- **Open-Source and Collaborative**: HomoScriptor encourages community collaboration, allowing contributors to add new categories, tasks, and enhance the dataset's overall quality.

## Getting Started

1. Clone the HomoScriptor repository: `git clone https://github.com/fredi-python/HomoScriptor.git`
2. Navigate to the desired category's JSON file.
3. Access the instructions and corresponding outputs for training your LLM.

## Contributing

We welcome contributions from the community to expand and improve the HomoScriptor dataset. If you would like to contribute, please follow the guidelines outlined in the [CONTRIBUTING](https://github.com/fredi-python/HomoScriptor/blob/main/CONTRIBUTING.md) file.
